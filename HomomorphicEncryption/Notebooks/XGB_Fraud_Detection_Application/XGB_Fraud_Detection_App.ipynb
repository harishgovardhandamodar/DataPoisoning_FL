{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "maritime-jumping",
   "metadata": {},
   "source": [
    "# Fruad Detection via XGBoost Classifier\n",
    "\n",
    "This notebook shows how to train and run an XGBoost model to identify fraud over encrypted data. The dataset is based on fraud detection <a href=\"https://www.kaggle.com/datasets/dssouvikganguly/application-datacsv\"> dataset</a>. This notebook uses the first 10 features of the dataset (5 numerical, 5 categorical), where the target field is a boolean indicating fraud ('1' is fraud)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-thickness",
   "metadata": {},
   "source": [
    "The dataset attributes are:\n",
    "\n",
    "|Attribute|Description|Values|\n",
    "|---|---|---|\n",
    "|SK_ID_CURR|Loan application ID|Integer (100000-500000)|\n",
    "|TARGET|The label|Categorial, 1 for fraud, 0 otherwise\n",
    "|NAME_CONTRACT_TYPE| The type of loan|Categorial, \"Cash loans\" or \"Revolving loans\"|\n",
    "|CODE_GENDER|The gender of the client|Categorial, 'M' for male, 'F' for Female|\n",
    "|FLAG_OWN_CAR|A boolean represents  if the client has car|Categorial, 'Y' for Yes, 'N' for no|\n",
    "|FLAG_OWN_REALTY|A boolean represents  if the client has realty|Categorial, 'Y' for Yes, 'N' for no|\n",
    "|CNT_CHILDREN|It represents the number of children a client has|Integer|\n",
    "|AMT_INCOME_TOTAL|Details on the requested loan|Numerical|\n",
    "|AMT_CREDIT|Details on the requested loan|Numerical|\n",
    "|AMT_ANNUITY|Details on the requested loan|Numerical|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fiscal-conducting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "##### For reproducibility\n",
    "from numpy.random import seed\n",
    "seed_value= 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "seed(seed_value)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import h5py\n",
    "\n",
    "import random\n",
    "import sklearn_json as skljson\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sys\n",
    "from  preprocessor import Preprocessor\n",
    "TASK_NAME = \"fraud_detection_xgb\"\n",
    "run_with_gpu = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structured-authorization",
   "metadata": {},
   "source": [
    "### Data loading\n",
    "Please refer to the dataset <a href=\"https://www.kaggle.com/datasets/dssouvikganguly/application-datacsv\">documentation</a> for the complete list of attributes and their description.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "documented-finger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0           0      100002       1         Cash loans           M            N   \n",
       "1           1      100003       0         Cash loans           F            N   \n",
       "2           2      100004       0    Revolving loans           M            Y   \n",
       "3           3      100006       0         Cash loans           F            N   \n",
       "4           4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \n",
       "0               Y             0          202500.0    406597.5  \n",
       "1               N             0          270000.0   1293502.5  \n",
       "2               Y             0           67500.0    135000.0  \n",
       "3               Y             0          135000.0    312682.5  \n",
       "4               Y             0          121500.0    513000.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./datasets/fraud_detection.csv\")\n",
    "df = df.iloc[0:100000,0:10]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-region",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "We first convert the categorial features (in the table below) to indicator vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-microphone",
   "metadata": {},
   "source": [
    "Subsequently, we split every row into its target value (y) and predicates (X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "analyzed-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
      "43660       43660      150542         Cash loans           M            Y   \n",
      "87278       87278      201297         Cash loans           F            N   \n",
      "14317       14317      116701         Cash loans           F            N   \n",
      "81932       81932      195014         Cash loans           F            N   \n",
      "95321       95321      210668         Cash loans           F            Y   \n",
      "...           ...         ...                ...         ...          ...   \n",
      "73441       73441      185154         Cash loans           F            N   \n",
      "1341         1341      101575    Revolving loans           M            N   \n",
      "71987       71987      183485         Cash loans           F            N   \n",
      "26910       26910      131278    Revolving loans           F            N   \n",
      "24890       24890      128948         Cash loans           F            N   \n",
      "\n",
      "      FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \n",
      "43660               Y             1           76500.0    824823.0  \n",
      "87278               Y             0          225000.0    276277.5  \n",
      "14317               Y             0          144000.0    983299.5  \n",
      "81932               Y             0          292500.0   1467612.0  \n",
      "95321               Y             2          171000.0    640080.0  \n",
      "...               ...           ...               ...         ...  \n",
      "73441               N             0           40500.0    450000.0  \n",
      "1341                N             0          112500.0    337500.0  \n",
      "71987               Y             0          225000.0    945000.0  \n",
      "26910               Y             0           90000.0    247500.0  \n",
      "24890               Y             0          202500.0    755190.0  \n",
      "\n",
      "[20000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "y_train = train[\"TARGET\"]\n",
    "y_test = test[\"TARGET\"]\n",
    "x_train = train.drop(\"TARGET\",axis=1)\n",
    "x_test = test.drop(\"TARGET\",axis=1)\n",
    "print(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-antigua",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "\n",
    "We split the dataset into the training (x_train, y_train) and test (x_test, y_test) sets and scale their features. \n",
    "\n",
    "We convert the categorial features (in the table below) to indicator vectors. \n",
    "\n",
    "Subsequently, we split the test set into test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "brilliant-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep = Preprocessor()\n",
    "x_train = prep.fit_transform(x_train)\n",
    "x_test = prep.transform(x_test)\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=4096, random_state=5, stratify=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-salmon",
   "metadata": {},
   "source": [
    "For later use in HE, we save the different preprocessed datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "involved-dressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving x_test of shape (15904, 9) in ./datasets/x_test.h5\n",
      "Saving y_test of shape (15904,) in ./datasets/x_test.h5\n",
      "Saving x_train of shape (80000, 9) in ./datasets/x_train.h5\n",
      "Saving y_train of shape (80000,) in ./datasets/x_train.h5\n",
      "Saving x_val of shape (4096, 9) in ./datasets/x_val.h5\n",
      "Saving y_val of shape (4096,) in ./datasets/x_val.h5\n"
     ]
    }
   ],
   "source": [
    "def save_data_set(x, y, data_type, path, s=''):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    fname=os.path.join(path, f'x_{data_type}{s}.h5')\n",
    "    print(\"Saving x_{} of shape {} in {}\".format(data_type, x.shape, fname))\n",
    "    xf = h5py.File(fname, 'w')\n",
    "    xf.create_dataset('x_{}'.format(data_type), data=x)\n",
    "    xf.close()\n",
    "\n",
    "    print(\"Saving y_{} of shape {} in {}\".format(data_type, y.shape, fname))\n",
    "    yf = h5py.File(os.path.join(path, f'y_{data_type}{s}.h5'), 'w')\n",
    "    yf.create_dataset(f'y_{data_type}', data=y)\n",
    "    yf.close()\n",
    "\n",
    "datasets_dir = \"./datasets/\"\n",
    "model_dir = \"./model/\"\n",
    "\n",
    "save_data_set(x_test, y_test, data_type='test', path=datasets_dir)\n",
    "save_data_set(x_train, y_train, data_type='train', path=datasets_dir)\n",
    "save_data_set(x_val, y_val, data_type='val', path=datasets_dir)\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "prep.save(os.path.join(model_dir, \"prep.pickle\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5c3a5e",
   "metadata": {},
   "source": [
    "### Training a XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "individual-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb model ready\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier(eta=0.2, gamma=3.6, max_depth=3,scale_pos_weight =10, min_child_weight=3, subsample=0.8, objective=\"binary:logistic\", eval_metric = \"aucpr\", n_estimators=5)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print('xgb model ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce5c47",
   "metadata": {},
   "source": [
    "For later use in HE, we save the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f6b171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to  ./model/fraud_detection_xgb_model.json\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    fname = os.path.join(path, f\"{TASK_NAME}_model.json\")\n",
    "    model.save_model(fname)\n",
    "    #skljson.to_json(model, fname)\n",
    "    print(\"Saved model to \",fname)\n",
    "\n",
    "save_model(clf, model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a38f9f",
   "metadata": {},
   "source": [
    "### Using the model for classifying cleartest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "462437a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872d294c",
   "metadata": {},
   "source": [
    "Confusion Matrix - TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "128a8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.575\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.83     14560\n",
      "           1       0.13      0.41      0.19      1344\n",
      "\n",
      "    accuracy                           0.71     15904\n",
      "   macro avg       0.53      0.58      0.51     15904\n",
      "weighted avg       0.86      0.71      0.77     15904\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10782  3778]\n",
      " [  793   551]]\n"
     ]
    }
   ],
   "source": [
    "f,t,thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(f\"AUC Score: {metrics.auc(f,t):.3f}\")\n",
    "print(\"Classification report:\")\n",
    "print(metrics.classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484df37",
   "metadata": {},
   "source": [
    "### Using the model for classifying encrypted data\n",
    "\n",
    "To run the model over encrypted samples with homomorphic encryption (HE), we first load the pyhelayers package and refer it to the directory \"output/\", where we saved the model and the relevant datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8955e913",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyhelayers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyhelayers\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyhelayers'"
     ]
    }
   ],
   "source": [
    "!pip install pyhelayers\n",
    "import pyhelayers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e86ffef",
   "metadata": {},
   "source": [
    "Load test data and labels from the h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b16121",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(datasets_dir + \"x_test.h5\") as f:\n",
    "    x_test = np.array(f[\"x_test\"])\n",
    "with h5py.File(datasets_dir + \"y_test.h5\") as f:\n",
    "    y_test = np.array(f[\"y_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9af7e-8f38-4f79-af31-06d214f74e16",
   "metadata": {},
   "source": [
    "### Compute the feature ranges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d049504-d324-4214-8c14-86a032122304",
   "metadata": {},
   "source": [
    "Our implementaiton requires the users to specify the minimum and maximum values of each feature. Here, we extract this info from the training data and assume it will also be relevant to the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63993415-b48c-4f73-b85b-57a9d0d728b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_range(col):\n",
    "    return (col.min(), col.max())\n",
    "\n",
    "feature_ranges = []\n",
    "for col in x_train.T:\n",
    "    feature_ranges.append(get_feature_range(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76c1f7f",
   "metadata": {},
   "source": [
    "Load a plain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967730dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded plain model\n"
     ]
    }
   ],
   "source": [
    "hyper_params = pyhelayers.PlainModelHyperParams()\n",
    "hyper_params.feature_ranges = feature_ranges\n",
    "# hyper_params.grep = 3\n",
    "# hyper_params.frep = 1\n",
    "hyper_params.verbose = False\n",
    "\n",
    "plain_xgb = pyhelayers.PlainModel.create(hyper_params, [os.path.join(model_dir, f\"{TASK_NAME}_model.json\")]) \n",
    "print(\"loaded plain model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ce704",
   "metadata": {},
   "source": [
    "Apply automatic optimziations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737ab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using SEAL backend\n"
     ]
    }
   ],
   "source": [
    "he_run_req = pyhelayers.HeRunRequirements()\n",
    "if hasattr(pyhelayers, \"HeaanContext\"):\n",
    "    print('Using HEaaN backend')\n",
    "    he_run_req.set_he_context_options([pyhelayers.HeaanContext()])\n",
    "else:\n",
    "    print('Using SEAL backend')\n",
    "    he_run_req.set_he_context_options([pyhelayers.SealCkksContext()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e972843",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = pyhelayers.HeModel.compile(plain_xgb, he_run_req)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95f1d7f",
   "metadata": {},
   "source": [
    "Intialize the HE context with the optimized configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08535539",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_context = pyhelayers.HeModel.create_context(profile)\n",
    "if run_with_gpu:\n",
    "    he_context.set_default_device(pyhelayers.DeviceType.DEVICE_GPU)\n",
    "else:\n",
    "    he_context.set_default_device(pyhelayers.DeviceType.DEVICE_CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46de7e6",
   "metadata": {},
   "source": [
    "### 2.6. Initialize and encrypt the modelÂ¶\n",
    "We initialize the HE model using the plain model and the HE profile computed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee21a567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FHE model encrypted and initialized\n"
     ]
    }
   ],
   "source": [
    "xgb = plain_xgb.get_empty_he_model(he_context)\n",
    "xgb.encode_encrypt(plain_xgb, profile)\n",
    "print('FHE model encrypted and initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc83ecdb",
   "metadata": {},
   "source": [
    "We use the encrypted model over batches of 16 records at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb16b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "plain_samples = x_test.take(indices=range(0, batch_size), axis=0)\n",
    "labels = y_test.take(indices=range(0, batch_size), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa10a46",
   "metadata": {},
   "source": [
    "Encrypt input samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681cba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data encrypted\n"
     ]
    }
   ],
   "source": [
    "iop = xgb.create_io_processor()\n",
    "x_test_enc = iop.encode_encrypt_input_for_predict(plain_samples)\n",
    "print('input data encrypted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e328943-78c2-4141-aad7-846ffc898406",
   "metadata": {},
   "source": [
    "We perform FHE prediction on the encrypted test samples, using the encrypted model. The resulting predictions are encrypted as well, and will next be decrypted and compared to the expected labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a5b6a",
   "metadata": {},
   "source": [
    "### Run prediction over the encrypted data\n",
    "Now we perform inference of the 16 samples under encryption "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a5d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction ready\n"
     ]
    }
   ],
   "source": [
    "res = xgb.predict(x_test_enc)\n",
    "print('prediction ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c08b17",
   "metadata": {},
   "source": [
    "### Plaintext results\n",
    "\n",
    "Decrypting the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1318a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_plain = iop.decrypt_decode_output(res)\n",
    "res_plain = np.where(res_plain > 0.0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6316599f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "classification results\n",
      "=========================================\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Good, Prediction: Bad\n",
      "Label: Bad., Prediction: Bad\n",
      "Label: Bad., Prediction: Good.\n",
      "Label: Bad., Prediction: Bad\n"
     ]
    }
   ],
   "source": [
    "print('\\nclassification results')\n",
    "print('=========================================')\n",
    "for label,pred in zip(labels,res_plain):\n",
    "    print('Label:',('Good' if label==1 else 'Bad.'),end=', ')\n",
    "    print('Prediction:',('Bad' if pred[0]<0.5 else 'Good.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c39359-5c1a-4963-99e5-667cb20be6b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('fhe-py38-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "f497b8fb6983b2b7e8d6051f4315e544585546557ee2f98a631c292ad437c819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
